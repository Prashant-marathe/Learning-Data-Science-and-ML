{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c0d79f6",
   "metadata": {},
   "source": [
    "Hyperparameter tuning is the process of finding the optimal \"settings\" for your machine learning algorithm before the training actually begins.\n",
    "\n",
    "Think of **parameters** (weights and biases) as what the model learns *internally* from the data. Think of **hyperparameters** as the *external* configuration knobs you turn to control how the model learns.\n",
    "\n",
    "For **Logistic Regression**, the most critical knobs control **regularization** (preventing overfitting).\n",
    "\n",
    "#### 1. Key Hyperparameters in Logistic Regression\n",
    "\n",
    "\n",
    "* **`C` (Inverse of Regularization Strength):**\n",
    "    * This is the most important setting.\n",
    "    * **Small `C` (e.g., 0.01):** Strong regularization. The model simplifies the decision boundary (good for noisy data, prevents overfitting).\n",
    "    * **Large `C` (e.g., 100):** Weak regularization. The model tries to fit every data point perfectly (risk of overfitting).\n",
    "\n",
    "\n",
    "* **`penalty`:**\n",
    "    * Decides *how* to penalize complex models.\n",
    "    * **`'l2'` (Ridge):** Shrinks coefficients toward zero (default).\n",
    "    * **`'l1'` (Lasso):** Can shrink coefficients *to* zero (performs feature selection).\n",
    "    * **`'elasticnet'`:** A mix of both.\n",
    "\n",
    "\n",
    "* **`solver`:**\n",
    "    * The mathematical algorithm used to find the weights.\n",
    "    * Examples: `liblinear` (good for small binary datasets), `saga` (good for large datasets and supports ElasticNet).\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. What is \"Cross Validation\"\n",
    "\n",
    "**CV stands for Cross-Validation.**\n",
    "When tuning, you cannot test on your final \"Test Set\" (that's cheating/data leakage). Instead, the algorithm:\n",
    "\n",
    "1. Splits your **Training Data** into  folds (e.g., 5 parts).\n",
    "2. Trains on 4 parts, validates on the 5th part.\n",
    "3. Repeats this 5 times and averages the score.\n",
    "\n",
    "This ensures the hyperparameters you choose are robust and not just lucky for one specific split of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "928041ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee6838ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "from sklearn.datasets import make_classification\n",
    "X, y = make_classification(n_samples=1000, n_features=10, random_state=55, n_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff40abc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.764892</td>\n",
       "      <td>0.614783</td>\n",
       "      <td>-0.682799</td>\n",
       "      <td>1.349154</td>\n",
       "      <td>-1.253422</td>\n",
       "      <td>-2.843722</td>\n",
       "      <td>-1.179356</td>\n",
       "      <td>0.871903</td>\n",
       "      <td>-2.162518</td>\n",
       "      <td>0.189528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.076614</td>\n",
       "      <td>0.750500</td>\n",
       "      <td>0.357315</td>\n",
       "      <td>1.609410</td>\n",
       "      <td>0.357707</td>\n",
       "      <td>1.475502</td>\n",
       "      <td>0.262632</td>\n",
       "      <td>2.063346</td>\n",
       "      <td>2.915461</td>\n",
       "      <td>-1.173271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.644742</td>\n",
       "      <td>0.531535</td>\n",
       "      <td>-0.850795</td>\n",
       "      <td>-1.772644</td>\n",
       "      <td>0.028788</td>\n",
       "      <td>1.232742</td>\n",
       "      <td>0.537949</td>\n",
       "      <td>-1.671866</td>\n",
       "      <td>0.015055</td>\n",
       "      <td>-0.807296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.726646</td>\n",
       "      <td>0.406491</td>\n",
       "      <td>-0.255955</td>\n",
       "      <td>-2.181476</td>\n",
       "      <td>0.921972</td>\n",
       "      <td>0.806065</td>\n",
       "      <td>-1.151218</td>\n",
       "      <td>-2.206911</td>\n",
       "      <td>-0.784092</td>\n",
       "      <td>0.110835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.266286</td>\n",
       "      <td>0.537875</td>\n",
       "      <td>-0.049964</td>\n",
       "      <td>2.086994</td>\n",
       "      <td>-0.824239</td>\n",
       "      <td>-0.739098</td>\n",
       "      <td>0.408712</td>\n",
       "      <td>2.118067</td>\n",
       "      <td>0.786320</td>\n",
       "      <td>0.405554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2  ...         7         8         9\n",
       "0 -0.764892  0.614783 -0.682799  ...  0.871903 -2.162518  0.189528\n",
       "1 -0.076614  0.750500  0.357315  ...  2.063346  2.915461 -1.173271\n",
       "2 -0.644742  0.531535 -0.850795  ... -1.671866  0.015055 -0.807296\n",
       "3  0.726646  0.406491 -0.255955  ... -2.206911 -0.784092  0.110835\n",
       "4 -0.266286  0.537875 -0.049964  ...  2.118067  0.786320  0.405554\n",
       "\n",
       "[5 rows x 10 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef968c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7206841f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23128940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((700, 10), (300, 10), (700,), (300,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6bec0ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61720549",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "#### **1. Class Overview**\n",
    "\n",
    "```python\n",
    "sklearn.linear_model.LogisticRegression(\n",
    "penalty='l2', dual=False, tol=0.0001, C=1.0, \n",
    "fit_intercept=True, intercept_scaling=1, \n",
    "class_weight=None, random_state=None, \n",
    "solver='lbfgs', max_iter=100, \n",
    "multi_class='auto', verbose=0, \n",
    "warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Critical Parameters for Tuning**\n",
    "\n",
    "In professional practice, you will spend 90% of your time tuning these four parameters. They determine the modelâ€™s ability to generalize and its computational efficiency.\n",
    "\n",
    "##### **A. `penalty` (Regularization Type)**\n",
    "\n",
    "* **Options:** `None`, `'l1'`, `'l2'`, `'elasticnet'` (Default: `'l2'`)\n",
    "* **Professional Context:** Used to prevent overfitting by penalizing large coefficients.\n",
    "* **`l2` (Ridge):** Shrinks coefficients but keeps them all. Good for general use.\n",
    "* **`l1` (Lasso):** Shrinks some coefficients to exactly zero. Useful for **feature selection** if you have many irrelevant features.\n",
    "* **`elasticnet`:** A combination of L1 and L2. Requires the `l1_ratio` parameter.\n",
    "\n",
    "\n",
    "\n",
    "##### **B. `C` (Inverse Regularization Strength)**\n",
    "\n",
    "* **Type:** `float` (Default: `1.0`)\n",
    "* **Tuning Range:** Typically logarithmic (e.g., `np.logspace(-4, 4, 20)`)\n",
    "* **Professional Context:** This is the most important \"knob.\"\n",
    "* **Small `C`:** High regularization (simpler model, high bias, low variance).\n",
    "* **Large `C`:** Low regularization (complex model, low bias, high variance).\n",
    "\n",
    "\n",
    "\n",
    "##### **C. `solver` (The Optimizer)**\n",
    "\n",
    "* **Options:** `'lbfgs'`, `'liblinear'`, `'newton-cg'`, `'newton-cholesky'`, `'sag'`, `'saga'`\n",
    "* **Selection Criteria:**\n",
    "* **`liblinear`:** Best for small datasets. Only supports OvR for multiclass.\n",
    "* **`lbfgs`:** The default. Robust for most medium-sized problems.\n",
    "* **`saga`:** The \"Swiss Army Knife.\" Only solver that supports all penalties (L1, L2, ElasticNet) and is fast for very large datasets.\n",
    "\n",
    "\n",
    "\n",
    "##### **D. `class_weight` (Imbalance Handling)**\n",
    "\n",
    "* **Options:** `None`, `'balanced'`, or a `dict` (Default: `None`)\n",
    "* **Professional Context:** If your dataset has 95% \"No\" and 5% \"Yes,\" set this to `'balanced'`. It automatically adjusts weights inversely proportional to class frequencies, ensuring the model doesn't ignore the minority class.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Secondary & Computational Parameters**\n",
    "\n",
    "These parameters rarely affect accuracy but significantly affect **stability** and **speed**.\n",
    "\n",
    "| Parameter | Type | Professional Insight |\n",
    "| --- | --- | --- |\n",
    "| **`max_iter`** | `int` | Default is 100. For large datasets or complex features, the solver often fails to converge. **Common fix:** Increase to 1,000 or 10,000. |\n",
    "| **`multi_class`** | `str` | `'ovr'` (One-vs-Rest) or `'multinomial'`. `'auto'` chooses based on the solver and data. |\n",
    "| **`tol`** | `float` | Tolerance for stopping criteria. If the improvement is less than `tol`, training stops. |\n",
    "| **`l1_ratio`** | `float` | Only used if `penalty='elasticnet'`. `0` is equivalent to L2, `1` is equivalent to L1. |\n",
    "| **`n_jobs`** | `int` | Set to `-1` to use all CPU cores during the \"One-vs-Rest\" multiclass phase. |\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Attributes (Post-Training Inspection)**\n",
    "\n",
    "A professional doesn't just look at the accuracy; they inspect the model's internals:\n",
    "\n",
    "* `.coef_`: The weights assigned to features. High absolute values indicate high feature importance.\n",
    "* `.intercept_`: The bias term.\n",
    "* `.n_iter_`: Useful to check if the model actually reached convergence or just stopped because it hit `max_iter`.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595306cd",
   "metadata": {},
   "source": [
    "*In Logistic Regression there are 2 main methods used to perform hyperparameter tuning: **1. Grid Search CV**, **2. Randomized Search CV***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "581ab2b7",
   "metadata": {},
   "source": [
    "##### 1. Grid Search CV:\"The Perfectionist\"\n",
    "Grid Search is a brute-force method. You define a discrete set of values for each hyperparameter, and the algorithm evaluates every single possible combination.\n",
    "\n",
    "* *How it works:* Imagine a grid. If you have 3 options for C and 2 options for penalty, Grid Search builds $3 \\times 2 = 6$ models (multiplied by the number of CV folds).\n",
    "\n",
    "* *Pros:* Guaranteed to find the best combination within the grid you provided.\n",
    "\n",
    "* *Cons:* Extremely computationally expensive. If you have many hyperparameters, the number of combinations grows exponentially.\n",
    "\n",
    "* *Example Scenario:*\n",
    "\n",
    "    * C = [0.1, 1, 10, 100] (4 values)\n",
    "\n",
    "    * penalty = ['l1', 'l2'] (2 values)\n",
    "    \n",
    "    * Total Iterations: $4 \\times 2 = 8$ combinations.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Core Functional Parameters**\n",
    "\n",
    "##### **`estimator` (Required)**\n",
    "\n",
    "* **Type:** `object`\n",
    "* **Description:** This is the model instance you want to tune (e.g., `LogisticRegression()`, `RandomForestClassifier()`).\n",
    "* **Professional Tip:** You can also pass a `Pipeline` object here. This is highly recommended to ensure that preprocessing steps (like scaling) are inside the cross-validation loop to prevent **data leakage**.\n",
    "\n",
    "##### **`param_grid` (Required)**\n",
    "\n",
    "* **Type:** `dict` or `list of dictionaries`\n",
    "* **Description:** The dictionary where keys are the hyperparameter names and values are the settings to try.\n",
    "* **Example:** `{'C': [0.1, 1], 'penalty': ['l1', 'l2']}`.\n",
    "* **Logic:** Grid Search performs a **Cartesian Product** of these values. The example above results in  unique combinations.\n",
    "\n",
    "##### **`scoring`**\n",
    "\n",
    "* **Type:** `str`, `callable`, or `list/dict` (Default: `None`)\n",
    "* **Description:** The metric used to evaluate the performance of the cross-validated model.\n",
    "* **Values:** Common strings include `'accuracy'`, `'f1'`, `'roc_auc'`, `'neg_mean_squared_error'`.\n",
    "* **Professional Tip:** For imbalanced datasets, never use the default (accuracy). Always specify `'f1'` or `'precision'`.\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Cross-Validation & Execution Parameters**\n",
    "\n",
    "##### **`cv`**\n",
    "\n",
    "* **Type:** `int` or `cross-validation generator` (Default: `5`)\n",
    "* **Description:** Determines the cross-validation splitting strategy.\n",
    "* **Logic:** An integer specifies the number of folds in a `(Stratified)KFold`.\n",
    "* **Professional Tip:** Use `cv=5` or `cv=10` as a standard. Higher values provide more robust estimates but increase training time linearly.\n",
    "\n",
    "##### **`refit`**\n",
    "\n",
    "* **Type:** `bool` or `str` (Default: `True`)\n",
    "* **Description:** After finding the best hyperparameters using cross-validation, should the model be retrained on the **entire dataset**?\n",
    "* **Professional Tip:** Always keep this `True`. It allows the final `grid_search` object to act as a model itself, so you can call `.predict()` immediately after tuning.\n",
    "\n",
    "##### **`n_jobs`**\n",
    "\n",
    "* **Type:** `int` (Default: `None`)\n",
    "* **Description:** Number of CPU cores to run in parallel.\n",
    "* **Values:** Set to `-1` to use all available processors. This drastically reduces the time spent waiting for the grid to finish.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Verbosity & Robustness Parameters**\n",
    "\n",
    "##### **`verbose`**\n",
    "\n",
    "* **Type:** `int`\n",
    "* **Description:** Controls the amount of messages printed during the search.\n",
    "* **Values:** `0` (silent), `1` (shows total tasks), `2` (shows time and score for every fold).\n",
    "* **Professional Tip:** Set `verbose=2` or `3` when running long grids so you can monitor progress and ensure your computer hasn't frozen.\n",
    "\n",
    "##### **`error_score`**\n",
    "\n",
    "* **Type:** `'raise'` or `numeric` (Default: `np.nan`)\n",
    "* **Description:** If one specific combination of hyperparameters fails (e.g., you try a solver that doesn't support L1 penalty), what should the model do?\n",
    "* **Professional Tip:** Setting this to `0` or `np.nan` allows the search to complete even if a few combinations error out, which is common when mixing solvers and penalties.\n",
    "\n",
    "---\n",
    "\n",
    "#### **4. Summary Table of Attributes (The Results)**\n",
    "\n",
    "Once you call `.fit()`, the object generates these attributes:\n",
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| **`best_params_`** | Dictionary of the specific settings that gave the best score. |\n",
    "| **`best_score_`** | The mean cross-validated score of the best estimator. |\n",
    "| **`best_estimator_`** | The actual model instance, refitted on the whole dataset. |\n",
    "| **`cv_results_`** | A massive dictionary (convertible to a Pandas DataFrame) showing the performance of **every** fold for **every** combination. |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c2d8ed",
   "metadata": {},
   "source": [
    "Let's perform hyperparameter tuning using parameters `C`, `penalty`, `solver`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f904c1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.1, 'penalty': 'l2', 'solver': 'newton-cg'}\n",
      "Best Accuracy: 0.8842857142857143\n",
      "Best Estimator:  LogisticRegression(C=0.1, max_iter=5000, solver='newton-cg')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# 1. Initialize the model\n",
    "logistic = LogisticRegression(max_iter=5000) # Increased max_iter for convergence\n",
    "\n",
    "# 2. Corrected Parameters\n",
    "# Note: We use a list of dictionaries to pair compatible penalties and solvers\n",
    "params = [\n",
    "    {\n",
    "        'penalty': ['l2'], \n",
    "        'C': [100, 10, 1.0, 0.1, 0.01],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'sag'] # Corrected 'ibfgs' to 'lbfgs'\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['l1', 'l2'], \n",
    "        'C': [100, 10, 1.0, 0.1, 0.01],\n",
    "        'solver': ['liblinear', 'saga']\n",
    "    },\n",
    "    {\n",
    "        'penalty': ['elasticnet'],\n",
    "        'C': [100, 10, 1.0, 0.1, 0.01],\n",
    "        'solver': ['saga'],\n",
    "        'l1_ratio': [0.5] # Required for elasticnet\n",
    "    }\n",
    "]\n",
    "\n",
    "# 3. Setup CV (Standard StratifiedKFold doesn't require 'groups')\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "\n",
    "# 4. Initialize GridSearchCV\n",
    "gridcv = GridSearchCV(\n",
    "    estimator=logistic, \n",
    "    param_grid=params, \n",
    "    scoring='accuracy', \n",
    "    cv=cv, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# 5. Fit the model\n",
    "gridcv.fit(X_train, y_train)\n",
    "\n",
    "# View the results\n",
    "print(\"Best Parameters:\", gridcv.best_params_)\n",
    "print(\"Best Accuracy:\", gridcv.best_score_)\n",
    "print(\"Best Estimator: \",gridcv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "960acb30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Predict the data\n",
    "y_pred = gridcv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2eaed55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance metrices\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5802b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Accuracy: \n",
      "0.8933333333333333\n"
     ]
    }
   ],
   "source": [
    "print(\"Model Accuracy: \")\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6c1c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      "[[134  15]\n",
      " [ 17 134]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion Matrix: \")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de3e9fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Values of Precision, Recall, and F1-score: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       149\n",
      "           1       0.90      0.89      0.89       151\n",
      "\n",
      "    accuracy                           0.89       300\n",
      "   macro avg       0.89      0.89      0.89       300\n",
      "weighted avg       0.89      0.89      0.89       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Values of Precision, Recall, and F1-score: ')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b06647f",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##### 2. Randomized Search CV : \"The Pragmatist\"\n",
    "\n",
    "Randomized Search does not try every combination. Instead, you define a range (distribution) of values, and the algorithm randomly samples a fixed number of combinations ($n\\_iter$) from that space.\n",
    "\n",
    "* *How it works:* It picks random points in the hyperparameter space to test.\n",
    "\n",
    "* *Pros:* Much faster. It is statistically likely to find a \"very good\" model (close to the optimal) in a fraction of the time. It allows you to search continuous ranges for C rather than fixed steps.\n",
    "\n",
    "* *Cons:* It might miss the absolute peak performance that Grid Search would hit if that peak lies between your random samples.\n",
    "\n",
    "* *Example Scenario:*\n",
    "    \n",
    "    * C = Any number between 0.1 and 100.\n",
    "\n",
    "    * penalty = ['l1', 'l2']\n",
    "\n",
    "    * Total Iterations: You set n_iter=10. It will try 10 random pairs.\n",
    "\n",
    "---\n",
    "\n",
    "#### **1. Core Functional Parameters**\n",
    "\n",
    "##### **`estimator` (Required)**\n",
    "\n",
    "* **Type:** `object`\n",
    "* **Description:** The model you want to tune (e.g., `LogisticRegression()`).\n",
    "* **Professional Tip:** Wrap this in a `Pipeline` (e.g., `Pipeline([('scaler', StandardScaler()), ('clf', LogisticRegression())])`) to ensure that scaling and other preprocessing steps are performed correctly within each cross-validation fold.\n",
    "\n",
    "##### **`param_distributions` (Required)**\n",
    "\n",
    "* **Type:** `dict` or `list of dicts`\n",
    "* **Description:** Dictionary where keys are parameter names and values are either **discrete lists** or **continuous distributions**.\n",
    "* **Professional Tip:** For parameters like `C` in Logistic Regression, use a continuous distribution (e.g., `scipy.stats.uniform`) rather than a fixed list. This allows the model to explore values that you might not have thought to include in a discrete grid.\n",
    "* *Example:* `{'C': scipy.stats.expon(scale=100), 'penalty': ['l1', 'l2']}`.\n",
    "\n",
    "\n",
    "\n",
    "##### **`n_iter` (Critical)**\n",
    "\n",
    "* **Type:** `int` (Default: `10`)\n",
    "* **Description:** The number of parameter settings that are sampled.\n",
    "* **Professional Tip:** This is your \"budget\" parameter. It balances runtime vs. solution quality. Increasing `n_iter` will likely lead to a better model but will take more time. Research suggests that with 60 iterations, you have a 95% probability of finding a solution within the top 5% of the optima.\n",
    "\n",
    "##### **`scoring`**\n",
    "\n",
    "* **Type:** `str` or `callable`\n",
    "* **Description:** Strategy to evaluate the performance of the cross-validated model.\n",
    "* **Professional Tip:** Always choose a metric aligned with your business goal (e.g., `'recall'` for fraud detection, `'f1'` for balanced precision/recall, or `'roc_auc'` for general classification ranking).\n",
    "\n",
    "---\n",
    "\n",
    "#### **2. Cross-Validation & Execution Parameters**\n",
    "\n",
    "##### **`cv`**\n",
    "\n",
    "* **Type:** `int` or `CV generator` (Default: `5`)\n",
    "* **Description:** Determines the cross-validation splitting strategy.\n",
    "* **Logic:** Usually uses `StratifiedKFold` for classification.\n",
    "\n",
    "##### **`random_state` (Essential for Reproducibility)**\n",
    "\n",
    "* **Type:** `int` or `RandomState instance`\n",
    "* **Description:** Seed for the random number generator.\n",
    "* **Professional Tip:** **Never leave this as None.** Because this algorithm relies on random sampling, your results will change every time you run the code unless you set a fixed `random_state`. This is vital for debugging and documenting model experiments.\n",
    "\n",
    "##### **`n_jobs`**\n",
    "\n",
    "* **Type:** `int`\n",
    "* **Description:** Number of jobs to run in parallel.\n",
    "* **Professional Tip:** Set to `-1` to utilize all CPU cores. Since Randomized Search involves many independent model fits, it is \"embarrassingly parallel\" and benefits significantly from multi-core processing.\n",
    "\n",
    "---\n",
    "\n",
    "#### **3. Attributes (Post-Execution Inspection)**\n",
    "\n",
    "| Attribute | Description |\n",
    "| --- | --- |\n",
    "| **`best_params_`** | The combination of parameters that achieved the highest score. |\n",
    "| **`best_score_`** | Mean cross-validated score of the best estimator. |\n",
    "| **`cv_results_`** | A dictionary containing all information about the search, including time taken for each fit and scores for every fold. |\n",
    "\n",
    "---\n",
    "\n",
    "#### **Why use Randomized over Grid Search?**\n",
    "\n",
    "1. **Efficiency:** It doesn't waste time on unimportant parameters. If one parameter has no impact on the outcome, Grid Search still repeats all combinations for it; Randomized Search moves on.\n",
    "2. **Granularity:** It can find the \"peak\" of performance that might fall *between* the fixed steps of a grid.\n",
    "3. **Scalability:** When you have 5+ hyperparameters, the number of combinations in a Grid Search becomes millions (the \"Curse of Dimensionality\"). Randomized Search stays constant at your `n_iter` limit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99b132ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'solver': 'liblinear', 'penalty': 'l2', 'C': 0.1}\n",
      "Best Accuracy: 0.8842857142857143\n",
      "Best Estimator:  LogisticRegression(C=0.1, solver='liblinear')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "randomcv = RandomizedSearchCV(estimator=logistic, param_distributions=params, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\n",
    "randomcv.fit(X_train, y_train)\n",
    "\n",
    "# View the results\n",
    "print(\"Best Parameters:\", randomcv.best_params_)\n",
    "print(\"Best Accuracy:\", randomcv.best_score_)\n",
    "print(\"Best Estimator: \",randomcv.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6c310de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the values and then find accuracy \n",
    "y_pred = randomcv.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0df94007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix: \n",
      " [[134  15]\n",
      " [ 17 134]]\n",
      "Accuracy Score:  0.8933333333333333\n",
      "Values of Recall, Precisio, and F1-score: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89       149\n",
      "           1       0.90      0.89      0.89       151\n",
      "\n",
      "    accuracy                           0.89       300\n",
      "   macro avg       0.89      0.89      0.89       300\n",
      "weighted avg       0.89      0.89      0.89       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "\n",
    "print('Confusion Matrix: \\n', confusion_matrix(y_test, y_pred))\n",
    "print('Accuracy Score: ', accuracy_score(y_test, y_pred))\n",
    "print('Values of Recall, Precisio, and F1-score: \\n', classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdef644a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
